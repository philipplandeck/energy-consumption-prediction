{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7555465,"sourceType":"datasetVersion","datasetId":4400347}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning Modelle\n1. [Entfernen von zukunftsbezogenen Features](#1)\n1. [Multiple Lineare Regression](#2)\n1. [Random Forest](#3)\n1. [XGBoost](#4)\n  1. [Permutation Importance](#5)\n  1. [F-Score](#6)\n  1. [SHAP Values](#7)\n1. [Performance-Vergleich](#8)","metadata":{}},{"cell_type":"code","source":"!pip install darts","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:08.936114Z","iopub.execute_input":"2024-02-05T17:46:08.936492Z","iopub.status.idle":"2024-02-05T17:46:38.581259Z","shell.execute_reply.started":"2024-02-05T17:46:08.936461Z","shell.execute_reply":"2024-02-05T17:46:38.579893Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting darts\n  Obtaining dependency information for darts from https://files.pythonhosted.org/packages/89/29/d5d086caa378240deb5d5e90982c772a8c4367e8688fb80754598ee35d14/darts-0.27.2-py3-none-any.whl.metadata\n  Downloading darts-0.27.2-py3-none-any.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m820.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: holidays>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from darts) (0.24)\nRequirement already satisfied: joblib>=0.16.0 in /opt/conda/lib/python3.10/site-packages (from darts) (1.3.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from darts) (3.7.4)\nCollecting nfoursid>=1.0.0 (from darts)\n  Downloading nfoursid-1.0.1-py3-none-any.whl (16 kB)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from darts) (1.24.3)\nCollecting pmdarima>=1.8.0 (from darts)\n  Obtaining dependency information for pmdarima>=1.8.0 from https://files.pythonhosted.org/packages/ec/2b/e7d18360d56396b62781ba4616527af49244d4bed51f0780646fa3953cc8/pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata\n  Downloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (7.8 kB)\nCollecting pyod>=0.9.5 (from darts)\n  Downloading pyod-1.1.2.tar.gz (160 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.5/160.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.10/site-packages (from darts) (2.31.0)\nRequirement already satisfied: scikit-learn>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from darts) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from darts) (1.11.4)\nRequirement already satisfied: shap>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from darts) (0.44.0)\nCollecting statsforecast>=1.4 (from darts)\n  Obtaining dependency information for statsforecast>=1.4 from https://files.pythonhosted.org/packages/d0/55/7ae7ac6c564cd1a27311b10eafdc82c99553f16a0aac39d946a6038186aa/statsforecast-1.7.2-py3-none-any.whl.metadata\n  Downloading statsforecast-1.7.2-py3-none-any.whl.metadata (27 kB)\nRequirement already satisfied: statsmodels>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from darts) (0.14.0)\nCollecting tbats>=1.1.0 (from darts)\n  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.60.0 in /opt/conda/lib/python3.10/site-packages (from darts) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from darts) (4.5.0)\nRequirement already satisfied: xarray>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from darts) (2023.12.0)\nRequirement already satisfied: xgboost>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from darts) (2.0.2)\nRequirement already satisfied: pytorch-lightning<=2.1.2,>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from darts) (2.1.2)\nRequirement already satisfied: tensorboardX>=2.1 in /opt/conda/lib/python3.10/site-packages (from darts) (2.6.2.2)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from darts) (2.0.0+cpu)\nRequirement already satisfied: pandas>=1.0.5 in /opt/conda/lib/python3.10/site-packages (from darts) (2.0.3)\nRequirement already satisfied: hijri-converter in /opt/conda/lib/python3.10/site-packages (from holidays>=0.11.1->darts) (2.3.1)\nRequirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.10/site-packages (from holidays>=0.11.1->darts) (0.3.1)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from holidays>=0.11.1->darts) (2.8.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (10.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->darts) (3.0.9)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->darts) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.5->darts) (2023.3)\nRequirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=1.8.0->darts) (3.0.0)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=1.8.0->darts) (1.26.15)\nRequirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/conda/lib/python3.10/site-packages (from pmdarima>=1.8.0->darts) (68.1.2)\nRequirement already satisfied: numba>=0.51 in /opt/conda/lib/python3.10/site-packages (from pyod>=0.9.5->darts) (0.57.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from pyod>=0.9.5->darts) (1.16.0)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (6.0.1)\nRequirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (2023.12.2)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.2.1)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning<=2.1.2,>=1.5.0->darts) (0.10.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->darts) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->darts) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.22.0->darts) (2023.11.17)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=1.0.1->darts) (3.2.0)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap>=0.40.0->darts) (0.0.7)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap>=0.40.0->darts) (2.2.1)\nCollecting fugue>=0.8.1 (from statsforecast>=1.4->darts)\n  Obtaining dependency information for fugue>=0.8.1 from https://files.pythonhosted.org/packages/ae/47/d3449da0b9cad85a361bc1003554710a5b612cf60bc2840096e93e5cdbb3/fugue-0.8.7-py3-none-any.whl.metadata\n  Downloading fugue-0.8.7-py3-none-any.whl.metadata (17 kB)\nCollecting utilsforecast>=0.0.24 (from statsforecast>=1.4->darts)\n  Obtaining dependency information for utilsforecast>=0.0.24 from https://files.pythonhosted.org/packages/b5/0f/f2ae41b947ba488a1bec7584fb03a5eaaaab69f1efac5d2737b6ac0eb4a3/utilsforecast-0.0.26-py3-none-any.whl.metadata\n  Downloading utilsforecast-0.0.26-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: patsy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from statsmodels>=0.14.0->darts) (0.5.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorboardX>=2.1->darts) (3.20.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->darts) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->darts) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->darts) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->darts) (3.1.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (3.8.5)\nCollecting triad>=0.9.3 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Obtaining dependency information for triad>=0.9.3 from https://files.pythonhosted.org/packages/5b/58/beaa3c5d123c456f293624a70be342972ebc1d72fc2a02513c8947ba8735/triad-0.9.5-py3-none-any.whl.metadata\n  Downloading triad-0.9.5-py3-none-any.whl.metadata (6.1 kB)\nCollecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\nCollecting qpd>=0.4.4 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Obtaining dependency information for qpd>=0.4.4 from https://files.pythonhosted.org/packages/56/1f/909bff3b693dc50e0e4318922a93d3047c948acd3011a8c39665cc125d19/qpd-0.4.4-py3-none-any.whl.metadata\n  Downloading qpd-0.4.4-py3-none-any.whl.metadata (6.4 kB)\nCollecting fugue-sql-antlr>=0.1.6 (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading fugue-sql-antlr-0.2.0.tar.gz (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sqlglot (from fugue>=0.8.1->statsforecast>=1.4->darts)\n  Obtaining dependency information for sqlglot from https://files.pythonhosted.org/packages/42/68/370cf101ead0f747c5c86943909eb990bdb8aa66a4db51e0242388968e6a/sqlglot-20.11.0-py3-none-any.whl.metadata\n  Downloading sqlglot-20.11.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.40.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->darts) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->darts) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<=2.1.2,>=1.5.0->darts) (1.3.1)\nCollecting antlr4-python3-runtime<4.12 (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts) (14.0.1)\nCollecting fs (from triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts)\n  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: appdirs~=1.4.3 in /opt/conda/lib/python3.10/site-packages (from fs->triad>=0.9.3->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\nDownloading darts-0.27.2-py3-none-any.whl (819 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.4/819.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pmdarima-2.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading statsforecast-1.7.2-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fugue-0.8.7-py3-none-any.whl (279 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading utilsforecast-0.0.26-py3-none-any.whl (38 kB)\nDownloading qpd-0.4.4-py3-none-any.whl (169 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.2/169.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triad-0.9.5-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sqlglot-20.11.0-py3-none-any.whl (356 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.5/356.5 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyod, fugue-sql-antlr\n  Building wheel for pyod (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyod: filename=pyod-1.1.2-py3-none-any.whl size=190289 sha256=a2857af741c7644a1854e91e181951900fc7a699e95000f5d83c77fd3aac446b\n  Stored in directory: /root/.cache/pip/wheels/81/1b/61/aa85b78c3c0c8871f4231e3f4a03bb23cecb7db829498380ee\n  Building wheel for fugue-sql-antlr (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fugue-sql-antlr: filename=fugue_sql_antlr-0.2.0-py3-none-any.whl size=158196 sha256=fa152fc8ed15537e404be8652caa81fe703fb387f7f6a23b1dbc35186bd2664c\n  Stored in directory: /root/.cache/pip/wheels/5a/b5/4e/216953a1c711da55de29ed7ecf158b4a5bf32ef93d69ad66dd\nSuccessfully built pyod fugue-sql-antlr\nInstalling collected packages: antlr4-python3-runtime, sqlglot, fs, utilsforecast, triad, pyod, nfoursid, pmdarima, fugue-sql-antlr, adagio, tbats, qpd, fugue, statsforecast, darts\nSuccessfully installed adagio-0.2.4 antlr4-python3-runtime-4.11.1 darts-0.27.2 fs-2.4.16 fugue-0.8.7 fugue-sql-antlr-0.2.0 nfoursid-1.0.1 pmdarima-2.0.4 pyod-1.1.2 qpd-0.4.4 sqlglot-20.11.0 statsforecast-1.7.2 tbats-1.1.3 triad-0.9.5 utilsforecast-0.0.26\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport warnings\nimport matplotlib.pyplot as plt\n# from sklearn.model_selection import train_test_split, RandomizedSearchCV\n# from sklearn.experimental import enable_iterative_imputer\n# from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom darts import TimeSeries\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\nfrom sklearn.model_selection import TimeSeriesSplit\n\nwarnings.filterwarnings('ignore')\nplt.style.use('ggplot')\n\nprint(\"Setup complete\")","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2024-02-05T17:46:38.584153Z","iopub.execute_input":"2024-02-05T17:46:38.584678Z","iopub.status.idle":"2024-02-05T17:46:40.485006Z","shell.execute_reply.started":"2024-02-05T17:46:38.584633Z","shell.execute_reply":"2024-02-05T17:46:40.483903Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Setup complete\n","output_type":"stream"}]},{"cell_type":"code","source":"def add_lag_features(df, columns):\n    \"\"\"\n    Fügt einem DataFrame Verzögerungs-Features (Lags) für die angegebenen Spalten hinzu. \n    Für jede Spalte in 'columns' wird ein Verzögerungs-Feature hinzugefügt.\n    Jedes Verzögerungs-Feature ist eine Verschiebung der Originalspalte um eine Stunde.\n\n    :param df: Pandas DataFrame, zu dem die Verzögerungs-Features hinzugefügt werden sollen.\n    :param columns: Liste der Spaltennamen, für die Verzögerungs-Features erstellt werden sollen.\n    :return: DataFrame mit den zusätzlichen Verzögerungs-Features.\n    \"\"\"\n    lagged_df = df.copy()\n    for column in columns:\n        lagged_df[f'{column}_lag_1'] = lagged_df[column].shift(1)\n    return lagged_df\n\n\ndef add_use_lags(df, lag_hours):\n    \"\"\"\n    Fügt einem DataFrame Verzögerungs-Features (Lags) für die Spalten 'use' hinzu. \n    Für jeden Verzögerungswert in 'lag_hours' wird ein Verzögerungs-Feature hinzugefügt.\n    Jedes Verzögerungs-Feature ist eine Verschiebung der Originalspalte um X Stunden.\n\n    :param df: Pandas DataFrame, zu dem die Verzögerungs-Features hinzugefügt werden sollen.\n    :param lag_hours: Liste der Verzögerungswerte, für die Verzögerungs-Features erstellt werden sollen.\n    :return: DataFrame mit den zusätzlichen Verzögerungs-Features.\n    \"\"\"\n    lagged_df = df.copy()\n    for lag in lag_hours:\n        lagged_df[f'use_lag_{lag}'] = lagged_df.use.shift(lag)\n    return lagged_df\n\n\ndef print_metrics(actual, predicted):\n    \"\"\"\n    Berechnet MAE, RMSE und MAPE zwischen den tatsächlichen und vorhergesagten Werten.\n    :param actual: Array der tatsächlichen Werte\n    :param predicted: Array der vorhergesagten Werte\n    \"\"\"\n    actual, predicted = np.array(actual), np.array(predicted)\n\n    mae = mean_absolute_error(actual, predicted)\n    rmse = np.sqrt(mean_squared_error(actual, predicted))\n    mape = mean_absolute_percentage_error(actual, predicted) * 100\n\n    print(f\"MAE: {round(mae, 2)}, RMSE: {round(rmse, 2)}, MAPE: {round(mape, 2)} %\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.486778Z","iopub.execute_input":"2024-02-05T17:46:40.487281Z","iopub.status.idle":"2024-02-05T17:46:40.498699Z","shell.execute_reply.started":"2024-02-05T17:46:40.487249Z","shell.execute_reply":"2024-02-05T17:46:40.497626Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def calc_metrics(df):\n    \"\"\"\n    Berechnet MAE, RMSE und MAPE zwischen den tatsächlichen und vorhergesagten Werten.\n    :param df: Ein Dataframe mit zwei Spalten, die die tatsächlichen und vorhergesagten Werte enthalten.\n    :return: Eine Liste mit den Werten für MAE, RMSE und MAPE.\n    \"\"\"\n    # In darts TimeSeries Objekte konvertieren\n    actual = TimeSeries.from_values(df.iloc[:, 0])\n    predicted = TimeSeries.from_values(df.iloc[:, 1])\n    \n    return [\n        mae(actual, predicted),\n        rmse(actual, predicted),\n        mape(actual, predicted)\n    ]\n\n\ndef print_avg_metrics(metrics_list):\n    \"\"\"\n    Berechnet MAE, RMSE und MAPE als Durchschnitt über alle folds und gibt diese in der Konsole aus.\n    :param metrics_list: Eine Liste von Listen, die jeweils die drei Werte für MAE, RMSE und MAPE enthalten.\n    \"\"\"\n    sum_mae = sum_rmse = sum_mape = 0.0\n    n_folds = len(metrics_list)\n    \n    for fold in metrics_list:\n        sum_mae += fold[0]\n        sum_rmse += fold[1]\n        sum_mape += fold[2]\n    \n    avg_mae = sum_mae / n_folds\n    avg_rmse = sum_rmse / n_folds\n    avg_mape = sum_mape / n_folds\n    \n    print(f\"MAE: {round(avg_mae, 2)}, RMSE: {round(avg_rmse, 2)}, MAPE: {round(avg_mape, 2)} %\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.501317Z","iopub.execute_input":"2024-02-05T17:46:40.501723Z","iopub.status.idle":"2024-02-05T17:46:40.514013Z","shell.execute_reply.started":"2024-02-05T17:46:40.501691Z","shell.execute_reply":"2024-02-05T17:46:40.513117Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def predict_next_24hours_features(model, train_X, train_y, test_X):\n    \"\"\"\n    Trainiert ein vorgegebenes Modell mit einer Serie von Trainingsdaten.\n    :param model: Ein angepasstes Modell aus der darts Bibliothek.\n    :return: Eine Liste mit vorhergesagten Werten für das entsprechende Modell und Trainingsdaten.\n    \"\"\"\n    model.fit(train_X, train_y)\n    preds = model.predict(test_X)\n    gerundete_werte = [round(wert, 2) for wert in preds]\n    print(gerundete_werte)\n    return gerundete_werte\n\n\ndef eval_model_features(df, cv, model, model_abb):\n    \"\"\"\n    Evaluiert ein vorgegebenes Modell für alle folds eines TimeSeriesSplit-Objekts.\n    :param df: Ein Dataframe, der einen Zeitstempel und eine Spalte 'use' mit realen Messwerten enthält.\n    :param cv: Das TimeSeriesSplit-Objekt, das Informationen zu den folds enthält.\n    :param model: Ein angepasstes Modell aus der darts Bibliothek.\n    :param model_abb: Ein Abkürzung für das Modell, nach der die Spalte für die vorhergesagten Werte benannt wird.\n    :return: Eine Dataframe mit realen und vorhergesagten Werten für das entsprechende Modell.\n    \"\"\"\n    metrics_list = list()\n    prediction_df = pd.DataFrame()\n    \n    for train_indices, test_indices in cv.split(df.use):\n        train = df[df.index.isin(train_indices)].set_index('timestamp')\n        test = df[df.index.isin(test_indices)].set_index('timestamp')\n        \n        # Imputation\n        simple_imputer = SimpleImputer(strategy='median')\n        train_data = pd.DataFrame(simple_imputer.fit_transform(train), index=train.index, columns=train.columns)\n        test_data = pd.DataFrame(simple_imputer.transform(test), index=test.index, columns=test.columns)\n        \n        # In darts TimeSeries Objekte konvertieren\n        # train_series = TimeSeries.from_series(train_data)\n        train_y = train_data.use\n        train_X = train_data.drop('use', axis=1)\n        test_y = test_data.use\n        test_X = test_data.drop('use', axis=1)\n        ###\n        \n        temp_df = pd.DataFrame(test_y)\n        temp_df.rename(columns={'use': 'actual'}, inplace=True)\n        temp_df[f\"{model_abb}_preds\"] = predict_next_24hours_features(model, train_X, train_y, test_X)\n        prediction_df = pd.concat([prediction_df, temp_df])\n        \n        fold_metrics = calc_metrics(temp_df)\n        metrics_list.append(fold_metrics)\n    \n    print_avg_metrics(metrics_list)\n    return prediction_df","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.515439Z","iopub.execute_input":"2024-02-05T17:46:40.516180Z","iopub.status.idle":"2024-02-05T17:46:40.531145Z","shell.execute_reply.started":"2024-02-05T17:46:40.516137Z","shell.execute_reply":"2024-02-05T17:46:40.530366Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/ps-ds3/ps_ds3.csv\")\ndf.timestamp = pd.to_datetime(df.timestamp)\ndf.set_index('timestamp', inplace=True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.532388Z","iopub.execute_input":"2024-02-05T17:46:40.532790Z","iopub.status.idle":"2024-02-05T17:46:40.698587Z","shell.execute_reply.started":"2024-02-05T17:46:40.532760Z","shell.execute_reply":"2024-02-05T17:46:40.697532Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                         use  outdoor_temp  app_outdoor_temp  humidity  \\\ntimestamp                                                                \n2018-01-01 00:00:00  0.58575         -3.43             -7.00      0.86   \n2018-01-01 01:00:00  0.43750         -3.75             -7.14      0.83   \n2018-01-01 02:00:00  0.47875         -3.89             -7.26      0.79   \n2018-01-01 03:00:00  0.52275         -3.91             -7.38      0.75   \n2018-01-01 04:00:00  0.41825         -3.93             -7.54      0.73   \n\n                     is_holiday  hour  wday  day  month  is_off_day  ...  \\\ntimestamp                                                            ...   \n2018-01-01 00:00:00        True     0     0    1      1        True  ...   \n2018-01-01 01:00:00        True     1     0    1      1        True  ...   \n2018-01-01 02:00:00        True     2     0    1      1        True  ...   \n2018-01-01 03:00:00        True     3     0    1      1        True  ...   \n2018-01-01 04:00:00        True     4     0    1      1        True  ...   \n\n                     furnace  kitchenapp  livingroom  microwave   oven  \\\ntimestamp                                                                \n2018-01-01 00:00:00      NaN         NaN         NaN        NaN  0.008   \n2018-01-01 01:00:00      NaN         NaN         NaN        NaN  0.008   \n2018-01-01 02:00:00      NaN         NaN         NaN        NaN  0.008   \n2018-01-01 03:00:00      NaN         NaN         NaN        NaN  0.008   \n2018-01-01 04:00:00      NaN         NaN         NaN        NaN  0.008   \n\n                     refrigerator  utilityroom  venthood  arima_preds  \\\ntimestamp                                                               \n2018-01-01 00:00:00           NaN          NaN       NaN          NaN   \n2018-01-01 01:00:00           NaN          NaN       NaN          NaN   \n2018-01-01 02:00:00           NaN          NaN       NaN          NaN   \n2018-01-01 03:00:00           NaN          NaN       NaN          NaN   \n2018-01-01 04:00:00           NaN          NaN       NaN          NaN   \n\n                     es_preds  \ntimestamp                      \n2018-01-01 00:00:00       NaN  \n2018-01-01 01:00:00       NaN  \n2018-01-01 02:00:00       NaN  \n2018-01-01 03:00:00       NaN  \n2018-01-01 04:00:00       NaN  \n\n[5 rows x 27 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>use</th>\n      <th>outdoor_temp</th>\n      <th>app_outdoor_temp</th>\n      <th>humidity</th>\n      <th>is_holiday</th>\n      <th>hour</th>\n      <th>wday</th>\n      <th>day</th>\n      <th>month</th>\n      <th>is_off_day</th>\n      <th>...</th>\n      <th>furnace</th>\n      <th>kitchenapp</th>\n      <th>livingroom</th>\n      <th>microwave</th>\n      <th>oven</th>\n      <th>refrigerator</th>\n      <th>utilityroom</th>\n      <th>venthood</th>\n      <th>arima_preds</th>\n      <th>es_preds</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-01-01 00:00:00</th>\n      <td>0.58575</td>\n      <td>-3.43</td>\n      <td>-7.00</td>\n      <td>0.86</td>\n      <td>True</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.008</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 01:00:00</th>\n      <td>0.43750</td>\n      <td>-3.75</td>\n      <td>-7.14</td>\n      <td>0.83</td>\n      <td>True</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.008</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 02:00:00</th>\n      <td>0.47875</td>\n      <td>-3.89</td>\n      <td>-7.26</td>\n      <td>0.79</td>\n      <td>True</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.008</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 03:00:00</th>\n      <td>0.52275</td>\n      <td>-3.91</td>\n      <td>-7.38</td>\n      <td>0.75</td>\n      <td>True</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.008</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2018-01-01 04:00:00</th>\n      <td>0.41825</td>\n      <td>-3.93</td>\n      <td>-7.54</td>\n      <td>0.73</td>\n      <td>True</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.008</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n## 1. Entfernen von zukunftsbezogenen Features","metadata":{}},{"cell_type":"code","source":"future_features = ['outdoor_temp', 'app_outdoor_temp', 'humidity', 'air', 'bathroom', 'car', 'clotheswasher', 'dishwasher', 'drye',\n                   'dryg', 'furnace', 'kitchenapp', 'livingroom', 'microwave', 'oven', 'refrigerator', 'utilityroom', 'venthood']\n\n# Verzögerungs-Features hinzufügen und zukunftsbezogene Features entfernen, um Data Leakage zu verhindern\ndf = add_lag_features(df, future_features)\ndf.drop(future_features, axis=1, inplace=True)\n\n# Verzögerungs-Features für Spalte use für relevante Zeiten aus der Vergangenheit (nur für use, da sonst zu viele Features)\nlag_hours = [1, 2, 3, 4, 5, 6, 24, 2*24, 3*24, 7*24]\ndf = add_use_lags(df, lag_hours)\n\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.700100Z","iopub.execute_input":"2024-02-05T17:46:40.700755Z","iopub.status.idle":"2024-02-05T17:46:40.757665Z","shell.execute_reply.started":"2024-02-05T17:46:40.700713Z","shell.execute_reply":"2024-02-05T17:46:40.756502Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 8760 entries, 2018-01-01 00:00:00 to 2018-12-31 23:00:00\nData columns (total 37 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   use                     8662 non-null   float64\n 1   is_holiday              8760 non-null   bool   \n 2   hour                    8760 non-null   int64  \n 3   wday                    8760 non-null   int64  \n 4   day                     8760 non-null   int64  \n 5   month                   8760 non-null   int64  \n 6   is_off_day              8760 non-null   bool   \n 7   arima_preds             8592 non-null   float64\n 8   es_preds                8592 non-null   float64\n 9   outdoor_temp_lag_1      8757 non-null   float64\n 10  app_outdoor_temp_lag_1  8757 non-null   float64\n 11  humidity_lag_1          8757 non-null   float64\n 12  air_lag_1               8616 non-null   float64\n 13  bathroom_lag_1          8369 non-null   float64\n 14  car_lag_1               8616 non-null   float64\n 15  clotheswasher_lag_1     8369 non-null   float64\n 16  dishwasher_lag_1        8369 non-null   float64\n 17  drye_lag_1              8616 non-null   float64\n 18  dryg_lag_1              8369 non-null   float64\n 19  furnace_lag_1           8369 non-null   float64\n 20  kitchenapp_lag_1        8369 non-null   float64\n 21  livingroom_lag_1        8369 non-null   float64\n 22  microwave_lag_1         8369 non-null   float64\n 23  oven_lag_1              8616 non-null   float64\n 24  refrigerator_lag_1      8369 non-null   float64\n 25  utilityroom_lag_1       8369 non-null   float64\n 26  venthood_lag_1          8369 non-null   float64\n 27  use_lag_1               8661 non-null   float64\n 28  use_lag_2               8660 non-null   float64\n 29  use_lag_3               8659 non-null   float64\n 30  use_lag_4               8658 non-null   float64\n 31  use_lag_5               8657 non-null   float64\n 32  use_lag_6               8656 non-null   float64\n 33  use_lag_24              8638 non-null   float64\n 34  use_lag_48              8614 non-null   float64\n 35  use_lag_72              8590 non-null   float64\n 36  use_lag_168             8494 non-null   float64\ndtypes: bool(2), float64(31), int64(4)\nmemory usage: 2.4 MB\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prozentsatz der fehlenden Werte für jede Spalte\nmissing_share = df.isnull().mean() * 100\nsorted_missing_share = missing_share.sort_values(ascending=False)\n\nmax_column_name_len = max(len(column) for column in df.columns)\n\nfor column_name, percent_val in sorted_missing_share.items():\n    if percent_val > 0:\n        print(f\"{column_name.ljust(max_column_name_len)}\\t{percent_val:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.759130Z","iopub.execute_input":"2024-02-05T17:46:40.759424Z","iopub.status.idle":"2024-02-05T17:46:40.771750Z","shell.execute_reply.started":"2024-02-05T17:46:40.759398Z","shell.execute_reply":"2024-02-05T17:46:40.770761Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"dryg_lag_1            \t4.46%\nbathroom_lag_1        \t4.46%\nventhood_lag_1        \t4.46%\nutilityroom_lag_1     \t4.46%\nrefrigerator_lag_1    \t4.46%\nmicrowave_lag_1       \t4.46%\nlivingroom_lag_1      \t4.46%\nkitchenapp_lag_1      \t4.46%\nfurnace_lag_1         \t4.46%\ndishwasher_lag_1      \t4.46%\nclotheswasher_lag_1   \t4.46%\nuse_lag_168           \t3.04%\nuse_lag_72            \t1.94%\nes_preds              \t1.92%\narima_preds           \t1.92%\nuse_lag_48            \t1.67%\nair_lag_1             \t1.64%\ncar_lag_1             \t1.64%\ndrye_lag_1            \t1.64%\noven_lag_1            \t1.64%\nuse_lag_24            \t1.39%\nuse_lag_6             \t1.19%\nuse_lag_5             \t1.18%\nuse_lag_4             \t1.16%\nuse_lag_3             \t1.15%\nuse_lag_2             \t1.14%\nuse_lag_1             \t1.13%\nuse                   \t1.12%\nhumidity_lag_1        \t0.03%\noutdoor_temp_lag_1    \t0.03%\napp_outdoor_temp_lag_1\t0.03%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Performance von SimpleImputer(strategy='median') > KNNImputer, IterativeImputer, SimpleImputer(strategy='mean')","metadata":{}},{"cell_type":"code","source":"train, test = train_test_split(df, train_size=0.8, shuffle=False)\n\n# Imputation\nimputer = SimpleImputer(strategy='median')\ntrain_data = pd.DataFrame(imputer.fit_transform(train), index=train.index, columns=train.columns)\ntest_data = pd.DataFrame(imputer.transform(test), index=test.index, columns=test.columns)\n\ntrain_y = train_data.use\ntrain_X = train_data.drop('use', axis=1)\ntest_y = test_data.use\ntest_X = test_data.drop('use', axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.773391Z","iopub.execute_input":"2024-02-05T17:46:40.773839Z","iopub.status.idle":"2024-02-05T17:46:40.867186Z","shell.execute_reply.started":"2024-02-05T17:46:40.773809Z","shell.execute_reply":"2024-02-05T17:46:40.866236Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n## 3. Multiple Lineare Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nforecast_hours = 24\n\nlr_model = LinearRegression()\nlr_model.fit(train_X, train_y)\n\nlr_predictions = lr_model.predict(test_X[:forecast_hours])\nprint_metrics(test_y[:forecast_hours], lr_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.872876Z","iopub.execute_input":"2024-02-05T17:46:40.873226Z","iopub.status.idle":"2024-02-05T17:46:40.928253Z","shell.execute_reply.started":"2024-02-05T17:46:40.873196Z","shell.execute_reply":"2024-02-05T17:46:40.926696Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"MAE: 0.47, RMSE: 0.79, MAPE: 61.27 %\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n## 4. Random Forest\n\"Für das systematische Tuning können Sie GridSearchCV oder RandomizedSearchCV aus Scikit-Learn verwenden.\"","metadata":{}},{"cell_type":"code","source":"rf_regressor = RandomForestRegressor()\n\n# Anzahl der Bäume im Wald\nn_estimators = np.arange(50, 1000, 50)\n# Anzahl der Features, die bei der Suche nach dem besten Split berücksichtigt werden sollen\nmax_features = [None, 'sqrt', 'log2']\n# Maximale Tiefe der Bäume\nmax_depth = np.arange(10, 100, 10)\n# Minimale Anzahl von Samples, die benötigt werden, um einen internen Knoten zu teilen\nmin_samples_split = np.arange(2, 10, 1)\n# Minimale Anzahl von Samples, die ein Blattknoten haben muss\nmin_samples_leaf = np.arange(1, 10, 1)\n# Ob Bootstrap-Proben beim Aufbau der Bäume verwendet werden sollen\nbootstrap = [True, False]\n\nrf_grid = {'n_estimators': n_estimators,\n           'max_features': max_features,\n           'max_depth': max_depth,\n           'min_samples_split': min_samples_split,\n           'min_samples_leaf': min_samples_leaf,\n           'bootstrap': bootstrap}\n\nrf_model = RandomizedSearchCV(estimator=rf_regressor, param_distributions=rf_grid, n_iter=100, cv=3, n_jobs = -1)\nrf_model.fit(train_X, train_y)\n\nbest_rf_params = rf_model.best_params_\nbest_rf_model = rf_model.best_estimator_\n\nrf_predictions = best_rf_model.predict(test_X[:forecast_hours])\nprint_metrics(test_y[:forecast_hours], rf_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-02-05T17:46:40.930010Z","iopub.execute_input":"2024-02-05T17:46:40.931062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_rf_params","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n## 5. XGBoost\nhttps://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning","metadata":{}},{"cell_type":"code","source":"xgb_regressor = XGBRegressor()\n\nxgb_grid = {\n    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n    'n_estimators': [100, 200, 300, 400],\n    'max_depth': [3, 4, 5, 6],\n    'min_child_weight': [1, 2, 3, 4],\n    'gamma': [0, 0.1, 0.2, 0.3],\n    'subsample': [0.7, 0.8, 0.9, 1.0],\n    'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n}\n\nxgb_model = RandomizedSearchCV(estimator=xgb_regressor, param_distributions=xgb_grid, n_iter=100, cv=3, n_jobs=-1)\nxgb_model.fit(train_X, train_y)\n\nbest_xgb_params = xgb_model.best_params_\nbest_xgb_model = xgb_model.best_estimator_\n\nxgb_predictions = best_xgb_model.predict(test_X[:forecast_hours])\nprint_metrics(test_y[:forecast_hours], xgb_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_xgb_model = XGBRegressor(**best_xgb_params, early_stopping_rounds=20)\ntest_xgb_model.fit(train_X, train_y, eval_set=[(train_X, train_y), (test_X, test_y)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_xgb_predictions = test_xgb_model.predict(test_X[:forecast_hours])\nprint_metrics(test_y[:forecast_hours], test_xgb_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimal_trees = test_xgb_model.best_iteration\nresults = test_xgb_model.evals_result()\n\nplt.figure(figsize=(12, 8))\nplt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\nplt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\nplt.axvline(optimal_trees, color=\"gray\", label=\"Optimal tree number\")\nplt.xlabel(\"Number of trees\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"6\"></a>\n## 5.1 Permutation Importance\nhttps://www.kaggle.com/code/dansbecker/permutation-importance","metadata":{}},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(best_xgb_model).fit(test_X, test_y)\neli5.show_weights(perm, feature_names=test_X.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"7\"></a>\n## 5.2 F-Score\n\nNein, der F-Score, der aus einer Methode wie .get_fscore() (typischerweise in Bibliotheken wie XGBoost verwendet) und die Feature-Importance, die durch Permutationswichtigkeit (Permutation Importance) ermittelt wird, sind nicht dasselbe. Sie basieren auf unterschiedlichen Methoden zur Bestimmung der Wichtigkeit von Features.\n\nF-Score aus .get_fscore() in XGBoost oder ähnlichen Bibliotheken:\n\nDieser basiert in der Regel auf der Anzahl der Male, dass ein Feature beim Aufbau der Bäume im Modell verwendet wird.\nIn Entscheidungsbaum-basierten Modellen wie XGBoost bedeutet ein höherer F-Score, dass das Feature häufiger verwendet wird, um die Bäume zu teilen, was auf eine höhere Wichtigkeit hindeutet.\nDies ist eine intrinsische Methode, die direkt aus dem Trainingsprozess des Modells stammt.\nPermutationswichtigkeit (Permutation Importance):\n\nBei der Permutationswichtigkeit wird die Wichtigkeit eines Features durch das Mischen (Permutieren) der Werte dieses Features über die Beobachtungen hinweg und das Beobachten der Aus\nwirkungen auf die Modellleistung ermittelt.\n\nWenn die Permutation eines Features zu einer erheblichen Verschlechterung der Modellleistung führt, deutet dies darauf hin, dass das Feature wichtig ist.\nDiese Methode ist modellagnostisch, was bedeutet, dass sie unabhängig vom verwendeten Modelltyp funktioniert. Sie misst den Einfluss eines Features auf die Vorhersagegenauigkeit des Modells.\nDer Hauptunterschied zwischen diesen beiden Methoden liegt in ihrer Herangehensweise:\n\nDer F-Score gibt an, wie oft ein Feature beim Aufbau der Bäume eines Entscheidungsbaummodells verwendet wurde. Es ist eine direktere Messung basierend auf dem Trainingsprozess des Modells.\nDie Permutationswichtigkeit misst, wie sich die Vorhersageleistung des Modells ändert, wenn die Werte eines Features zufällig geändert werden. Sie gibt Aufschluss darüber, wie sich die Unordnung eines Features auf die Genauigkeit des Modells auswirkt.\nBeide Methoden können nützliche Einblicke in die Wichtigkeit von Features geben, aber sie können unterschiedliche Ergebnisse liefern, je nach den Eigenschaften der Daten und des Modells. In der Praxis ist es oft sinnvoll, beide Methoden zu verwenden, um ein umfassenderes Bild der Feature-Wichtigkeit zu erhalten.\n\nBeispiel: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/","metadata":{}},{"cell_type":"code","source":"# Feature Labels\nfeature_labels = train_X.columns\n\n# Extrahieren des RandomForestRegressor aus dem besten Modell\nxgb_regressor = best_xgb_model\n\n# Extrahieren der Feature-Importances\nfeature_importances = xgb_regressor.feature_importances_\n\n# Überprüfen, ob die Anzahl der Features übereinstimmt\nif len(feature_labels) != len(feature_importances):\n    raise ValueError(\"Die Anzahl der Features im Modell stimmt nicht mit der Anzahl der ursprünglichen Features überein.\")\n    \n# Zuordnung der Feature-Namen\nimportance_df = pd.DataFrame({'feature': feature_labels, 'importance': feature_importances})\nimportance_df.sort_values(by='importance', ascending=False, inplace=True)\n\n# Erstellen des Plots\nplt.figure(figsize=(15, 4))\nplt.title(\"Feature Importances\")\nplt.bar(importance_df.feature, importance_df.importance, color='b')\nplt.xlabel('Features')\nplt.ylabel('Relative Importance')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"8\"></a>\n## 5.3 SHAP Values\nhttps://www.kaggle.com/code/dansbecker/shap-values\n\nhttps://www.kaggle.com/code/dansbecker/advanced-uses-of-shap-values","metadata":{}},{"cell_type":"code","source":"import shap\n\nexplainer = shap.TreeExplainer(xgb_regressor)\nshap_values = explainer.shap_values(test_X)\nshap.summary_plot(shap_values, test_X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Interpretation:\n* Vertical location shows what feature it is depicting\n* Color shows whether that feature was high or low for that row of the dataset\n* Horizontal location shows whether the effect of that value caused a higher or lower prediction.\n\nWenn use_lag_1 einen hohen Wert hat, wird ein hoher Verbrauch vorhergesagt.\n\nWenn use_lag_2 einen hohen Wert hat, wird ein niedriger Verbrauch vorhergesagt.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"9\"></a>\n## 6. Performance-Vergleich","metadata":{}},{"cell_type":"code","source":"df_comp = pd.DataFrame(test_y)\ndf_comp.rename(columns={'use': 'actual'}, inplace=True)\ndf_comp['arima_preds'] = df.arima_preds\ndf_comp['lr_preds'] = lr_predictions\ndf_comp['rf_preds'] = rf_predictions\ndf_comp['xgb_preds'] = xgb_predictions\ndf_comp.reset_index(inplace=True)\ndf_comp.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datapoints_per_week = 24 * 7\nlast_start_idx = len(df_comp) - 1 - datapoints_per_week\nstart_idx = random.randint(0, last_start_idx)\nend_idx = start_idx + datapoints_per_week\ndf_plot = df_comp[start_idx:end_idx]\n\nplt.figure(figsize=(20, 5))\nplt.plot(df_plot.timestamp, df_plot.actual, color='black', label='Realer Verbrauch')\nplt.plot(df_plot.timestamp, df_plot.arima_preds, color='orange', label='AutoARIMA')\nplt.plot(df_plot.timestamp, df_plot.xgb_preds, color='blue', label='XGBoost')\nplt.plot(df_plot.timestamp, df_plot.lr_preds, color='red', label='MLR')\nplt.plot(df_plot.timestamp, df_plot.rf_preds, color='green', label='Random Forest')\nplt.title('Vergleich zwischen realem Verbrauch und Vorhersagen')\nplt.xlabel('Zeit')\nplt.ylabel('Durchschnittlicher Verbrauch in kW')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}